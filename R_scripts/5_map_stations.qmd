---
title: "5_map_stations"
author: "Shayna A. Sura"
format: html
---

## Mapping the SEAMAP Trawl stations over time

```{r setup}


```




```{r load packages}
#| echo: false
#| message: false

library(tidyverse) # includes and loads the packages listed below
# library(readr)
# library(tidyr)
# library(dplyr)
# library(ggplot2)
# library(lubridate)

library(here) # helps with paths for files

# libraries for spatial data & animating it...
library(maps)
library(ggmap)
library(gganimate)
library(gifski) # for gif output
library(av) # for video output
library(png)
library(tools)

# not sure I need these libraries for what I'm trying to do.
# library(terra)
# library(geodata)
# library(predicts)

```





```{r reading in cleaned bio data}
#| echo: false
#| message: false

bio_data_clean <- read_csv(file = "data/clean_data/bio_data_clean.csv")

# head(bio_data_clean)

```

## obtain bounding coordinates for making maps

```{r}
#| echo: false
#| message: false

# Determine geographic extent of our data
# use ceiling() and floor() to round up and down to the nearest integer

max_lat <- ceiling(max(bio_data_clean$DECSLAT))
min_lat <- floor(min(bio_data_clean$DECSLAT))
max_long <- ceiling(max(bio_data_clean$DECSLON))
min_long <- floor(min(bio_data_clean$DECSLON))

# geo_extent <- ext(x = c(min_long,
#                         max_long,
#                         min_lat,
#                         max_lat))

```







```{r obtain GoM map}
#| echo: false
#| message: false


gulf_of_mexico_info <- map_data("usa", region = ".")
world_base_map <- map_data("world", region = ".")
usa_state_borders <- map_data("state", region = ".")

# base_map <- ggplot(data = gulf_of_mexico_info,
#                    mapping = aes (x = long, y = lat, group = group)) +
#   geom_polygon() +
#   coord_quickmap(xlim = c(min_long, max_long),
#                  ylim = c(min_lat, max_lat)) +
#   theme_void()


base_map <- ggplot(data = world_base_map,
                   mapping = aes (x = long, y = lat, group = group)) +
  geom_polygon(color = "black",
               fill = "white") +
  geom_polygon(data = usa_state_borders,
               color = "black",
               fill = "white") + 
  # coord_quickmap(xlim = c(min_long, max_long),
  #                ylim = c(min_lat, max_lat)) +
  coord_quickmap(xlim = c(-97.7, -79.9),
                 ylim = c(24, 31)) +
  theme(panel.background = element_rect(fill = c("#CFEFFF")),
        panel.border = element_rect(fill = NA,
                                    color = "black")
        ) +
  labs(x = "Longitude",
       y = "Latitude")


# base_map

# theme_void().  #EBF9FF #B3E5FC

#             (left = -98.438,
#              bottom = 12.082,
#              right = -79.519,
#              top = 33.505)

```



### Revise these maps and use the STAREC.csv raw data instead of the biological data to prevent duplication of station data points - because, currently, I am plotting the station data for each trawl multiple times (i.e., for each species caught in that trawl).


```{r}

# data_to_use_here_3 <- bio_data_clean
# data_to_use_here_3 <- post2010_clean_bio_data
data_to_use_here_3 <- bio_data_clean_yr2010_2022_m678


station_data <- data_to_use_here_3 %>% 
  group_by(STATIONID) %>% 
  summarize(CRUISEID = unique(CRUISEID),
            VESSEL = unique(VESSEL),
            CRUISE_NO = unique(CRUISE_NO),
            P_STA_NO = unique(P_STA_NO),
            YR = unique(YR),
            DEPTH_SSTA = unique(DEPTH_SSTA),
            MO_DAY_YR = unique(MO_DAY_YR),
            DECSLAT = unique(DECSLAT),
            DECSLON = unique(DECSLON),
            DECELAT = unique(DECELAT),
            DECELON = unique(DECELON),
            TEMP_SSURF = unique(TEMP_SSURF),
            TEMP_BOT = unique(TEMP_BOT),
            TEMP_SAIR = unique(TEMP_SAIR))

```

## how many trawls were done each year?

```{r}

stations_num_yr <- station_data %>% 
  group_by(YR) %>% 
  summarize(num_trawls = n(),
            dates = paste(unique(month(dmy(MO_DAY_YR))), sep = ";", collapse = "; "))

stations_num_yr
# write_csv(stations_num_yr, file = "output/stations_num_yr_v1.csv")
# write_csv(stations_num_yr, file = "output/stations_num_yr_v2.csv")
write_csv(stations_num_yr, file = "output/stations_num_yr_yr2010_2022_m678.csv")

## June and July (6 & 7) are consistent sampling months across all years, except 2020 and 2023
## October and November (10 & 11) are consistent sampling months across all years, except 1982 and 2023

### But about when surrounding months show up for trawls? e.g., May or August? Are those still part of summer sampling?
### What about when December shows up for trawls? Is that part of fall sampling?


```



```{r}

station_maps <- base_map +
  geom_point(data = station_data,
             na.rm = FALSE,
             aes(x = DECSLON,
                 y = DECSLAT,
                 group = NA,
                 fill = YR),
             size = 0.6,
             shape = 21,
             color = "darkorange4",
             fill = "orange",
             stroke = 0.05) +    # width of border line
  # scale_fill_viridis_d(name = "Year") +
    # scale_fill_gradient(low = "darkgray",
    #                    high = "springgreen",
    #                    limits = c(),
    #                    # breaks = c(),
    #                    # labels = c(),
    #                    name = "Year") +
  theme(text = element_text(family = "Times",
                            size = 14),
        plot.title = element_text(face = "bold"),
        axis.title = element_text(size = 12,
                                  face = "bold"),
        axis.text = element_text(size = 10),
        legend.title = element_text(size = 12,
                                    face = "bold",
                                    hjust = 0.5),
        legend.text = element_text(size = 10)) +
  labs(title = "2010 - 2022 June, July, & August Data") +
  facet_wrap(~YR)


station_maps
# ggsave("plots/stations_maps_v1.pdf", plot = station_maps, width = 9, height = 6.5)
# ggsave("plots/stations_maps_v2_2010_2022_summer.pdf", plot = station_maps, width = 9, height = 6.5)
ggsave("plots/station_maps_v3_yr2010_2022_m678.pdf", plot = station_maps, width = 9, height = 8.5)


```















# Visualize Data - Sampling Locations

```{r}

# library(leaflet)
# 
# 
# # how can I filter out the excess data from bio_data so I only have one set of coordinates for each trawl station?
# ## - the small_starec_data only has 1 row for each STATIONID.
# 
# trawl_locations <- inner_join(x = small_starec_data, y = bio_data, by = join_by(STATIONID))
# # hmm this is still giving me ALL the rows....
# # need to select out the unnecessary columns from bio_data?
# 
# 
# trawl_locations_2 <- (small_starec_data$STATIONID == bio_data$STATIONID) == TRUE # this doesn't work...
# 
# 
# leaflet(bio_data)

```







